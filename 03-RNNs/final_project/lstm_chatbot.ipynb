{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from src import data, vocab, model, train, evaluate\n",
    "\n",
    "# Set constants\n",
    "project_root = \"03-RNNs/final_project/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to whom did the virgin mari alleg appear in 18...</td>\n",
       "      <td>saint bernadett soubir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is in front of the notr dame main build</td>\n",
       "      <td>a copper statu of christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the basilica of the sacr heart at notr dame is...</td>\n",
       "      <td>the main build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the grotto at notr dame</td>\n",
       "      <td>a marian place of prayer and reflect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what sit on top of the main build at notr dame</td>\n",
       "      <td>a golden statu of the virgin mari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  to whom did the virgin mari alleg appear in 18...   \n",
       "1       what is in front of the notr dame main build   \n",
       "2  the basilica of the sacr heart at notr dame is...   \n",
       "3                    what is the grotto at notr dame   \n",
       "4     what sit on top of the main build at notr dame   \n",
       "\n",
       "                                 Answer  \n",
       "0                saint bernadett soubir  \n",
       "1              a copper statu of christ  \n",
       "2                        the main build  \n",
       "3  a marian place of prayer and reflect  \n",
       "4     a golden statu of the virgin mari  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data.load_data()\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98169, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For development I take only 5000 records\n",
    "data_df = data_df.iloc[:15000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_vocab = vocab.Vocab() # = Source\n",
    "A_vocab = vocab.Vocab() # = Target\n",
    "\n",
    "pairs = data.get_pairs(data_df)\n",
    "\n",
    "# Add Questions text to Q_vocab class and\n",
    "# Answers text to A_vocab class\n",
    "for pair in pairs:\n",
    "    Q_vocab.add_sentence(pair[0])\n",
    "    A_vocab.add_sentence(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 15, 10, 16, 17, 5, 18, 19, 20, 21]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_vocab.get_indexes_from_sentence(\"what is in front of the notr dame main build\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Question Answer pair:\n",
      "> Q: what type of process theolog doe c robert mesl promot \n",
      "< A: process natur ie a process theolog without god \n",
      "\n",
      "Question vocabulary (input): 9139 words\n",
      "Answer vocabulary (output): 9837 words\n"
     ]
    }
   ],
   "source": [
    "# Print random Question Answer pair\n",
    "random_pair = random.choice(pairs)\n",
    "print(\n",
    "    \"Random Question Answer pair:\\n> Q:\", random_pair[0], \"\\n< A:\", random_pair[1], \"\\n\"\n",
    ") \n",
    "\n",
    "# Print number of words in vocabularies\n",
    "print(\"Question vocabulary (input): {} words\\nAnswer vocabulary (output): {} words\".format(Q_vocab.n_words, A_vocab.n_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "hidden_size = 128 # encoder and decoder hidden size\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "\n",
    "model_name = \"seq2seq_exp_1\"\n",
    "\n",
    "seq2seq = model.Seq2Seq(\n",
    "    Q_vocab.n_words, \n",
    "    hidden_size, \n",
    "    A_vocab.n_words, \n",
    "    model_name\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of Tensors\n",
    "Q_tensors = [Q_vocab.get_tensor_from_sentence(pair[0]) for pair in pairs]\n",
    "A_tensors = [A_vocab.get_tensor_from_sentence(pair[1]) for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_weights = False\n",
    "if load_model_weights:\n",
    "    try:\n",
    "        model_state_dict = torch.load(f\"checkpoints/{model_name}_best_loss.pt\")\n",
    "        seq2seq.load_state_dict(model_state_dict)\n",
    "        print(\"Model weights loaded\")\n",
    "    except:\n",
    "        print(\"Model checkpoints not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    train.train(\n",
    "        Q_tensors, \n",
    "        A_tensors, \n",
    "        seq2seq, \n",
    "        epochs, \n",
    "        batch_size, \n",
    "        1, \n",
    "        learning_rate,\n",
    "        interactive_tracking=False,\n",
    "    )\n",
    "    # Save last model weights\n",
    "    torch.save(seq2seq.state_dict(), \"checkpoints/\" + seq2seq.model_name + \"_last_loss.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load model best weights for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_state_dict = torch.load(f\"checkpoints/{model_name}_best_loss.pt\")\n",
    "    seq2seq.load_state_dict(model_state_dict)\n",
    "    print(\"Model weights loaded\")\n",
    "except:\n",
    "    print(\"Model checkpoints not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Randomly evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Question: how much did schwarzenegg make from the film total recal on top of 15 of gross\n",
      "< Anwer: 10 million\n",
      "< Prediction: more\n",
      "\n",
      "> Question: what town is the crow and gate locat in\n",
      "< Anwer: crowborough\n",
      "< Prediction: east\n",
      "\n",
      "> Question: when did the zhengd emperor rule\n",
      "< Anwer: 1505â€“1521\n",
      "< Prediction: april\n",
      "\n",
      "> Question: which countri lie on congo northeast border\n",
      "< Anwer: central african republ\n",
      "< Prediction: the and and\n",
      "\n",
      "> Question: in how mani countri doe unfpa oper\n",
      "< Anwer: 150\n",
      "< Prediction: three\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_to_evaluate = 5\n",
    "for i in range(n_to_evaluate):\n",
    "    pair = random.choice(pairs)\n",
    "    pred_words = evaluate.evaluate(seq2seq, Q_vocab, A_vocab, pair)\n",
    "    print(\"> Question: {}\".format(pair[0]))\n",
    "    print(\"< Anwer: {}\".format(pair[1]))\n",
    "    print(\"< Prediction: {}\\n\".format(' '.join(pred_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
