{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ccbc8d-6852-4114-8bc4-009a69a52a8c",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d88153-f889-47ad-a3e6-2e7848762eb0",
   "metadata": {},
   "source": [
    "Autoencoders have a similar backbone (called encoder in this context) that produces a feature vector (called embedding in this context). However, they substitute the fully-connected layers (the head) with a decoder stage whose scope is to reconstruct the input image starting from the embeddings.\n",
    "\n",
    "Uses of autoencoders:\n",
    "- Compress data\n",
    "- Denoise data\n",
    "- Find outliers (do anomaly detection) in a dataset\n",
    "- Do inpainting (i.e., reconstruct missing areas of an image or a vector)\n",
    "- With some modifications, we can use autoencoders as generative models - models capable of generating new images\n",
    "\n",
    "Autoencoders are a form of **unsupervised learning**, since we learn without having a label.\n",
    "\n",
    "The loss function for autoencoders is the MSE between each pixel between the input and output image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e635c-8801-4001-82c8-249bb6f05239",
   "metadata": {},
   "source": [
    "## Linear autoencoders\n",
    "\n",
    "The encoder and decoder are made of simple Multi-Layer Perceptrons. The units that connect the encoder and decoder will be the _compressed representation_ (also called _embedding_).\n",
    "\n",
    "Since the images are normalized between 0 and 1, you will need to use a **sigmoid activation on the output layer** to get values that match this input value range.\n",
    "\n",
    "Example of very simple autoencoder with two linear layers:\n",
    "```python\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        ## encoder ##\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(encoding_dim)\n",
    "        )\n",
    "\n",
    "        ## decoder ##\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.auto_encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            self.encoder,\n",
    "            self.decoder\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define feedforward behavior \n",
    "        # and scale the *output* layer with a sigmoid activation function\n",
    "\n",
    "        encoded = self.auto_encoder(x)\n",
    "\n",
    "        # Reshape the output as an image\n",
    "        # remember that the shape should be (batch_size, channel_count, height, width)\n",
    "        return encoded.reshape((x.shape[0], 1, 28, 28))\n",
    "```\n",
    "\n",
    "The main parts of autoencoders:\n",
    "- the encoder = takes the input image and encodes into a 1d vector (the embedding),\n",
    "- the decoder = takes the embedding and generates an image from it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0064a7-ed3b-40d2-a239-9335dbe96748",
   "metadata": {},
   "source": [
    "## Anomaly detection\n",
    "\n",
    "An anomaly is a data element that is an outlier with respect to the rest of the dataset.\n",
    "\n",
    "How autoencoders work for anomaly detection:\n",
    "\n",
    "*Autoencoders compress the visual information contained in images into a compact, latent representation (the embedding) that has a much lower dimensionality than the input image. By asking the decoder to reconstruct the input from this compact representation, we force the network to learn an embedding that stores meaningful information about the content of the image. For example, in the solution I compressed 28 x 28 images (so 784 pixels) into a vector of only 32 elements, but I was still able to reconstruct most of the images very well.*\n",
    "\n",
    "*When applying it to a test set that the network has never seen, most images were reconstructed well, but some of them were not. This means that the compression that the network has learned on the training dataset works well for the vast majority of the examples in this new set, but not for these anomalous ones. These anomalies have characteristics that the network is not well equipped to reconstruct, and therefore the decoder cannot recreate them faithfully during decoding.*\n",
    "\n",
    "*Through scoring each example by the loss, we are able to identify anomalies by simply taking the examples with the highest loss.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c99a1-41ff-41b6-a1a0-6e37e074220b",
   "metadata": {},
   "source": [
    "## Upsampling\n",
    "\n",
    "Instead of using linear layers to decode the image, we could also upsample a compact representation (embedding) into a full resolution image. For example, we could use a Transposed Convolutional Layer, which can learn how to best upsample an image.\n",
    "\n",
    "### Transposed Convolutional Layer\n",
    "\n",
    "Transposed Convolution can perform an upsampling of the input with learned weights. In particular, a Transposed Convolution with a 2 x 2 filter and a stride of 2 will double the size of the input image.\n",
    "\n",
    "Whereas a Max Pooling operation with a 2 x 2 window and a stride of 2 reduces the input size by half, a Transposed Convolution with a 2 x 2 filter and a stride of 2 will double the input size.\n",
    "\n",
    "Example code in PyTorch:\n",
    "```python\n",
    "unpool = nn.ConvTranspose2d(input_ch, output_ch, kernel_size, stride=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7ceec-d280-4acb-a321-b0e36bf5ca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
